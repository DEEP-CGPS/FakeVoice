{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86a78941",
   "metadata": {},
   "source": [
    "# Benchmark Training: VGG, ResNet, ViT\n",
    "\n",
    "Este notebook prepara datos desde los ZIPs (`reals.zip`, `fakes.zip`), carga modelos **benchmark** de torchvision (VGG, ResNet, ViT) seg√∫n tu config y entrena **1 √©poca** por transformaci√≥n.\n",
    "\n",
    "**Requisitos previos**:\n",
    "- Carpeta del notebook: `notebooks/`\n",
    "- Zips en `../dataset/` (al nivel del repo): `reals.zip`, `fakes.zip`\n",
    "- (Opcional) modelos de usuario TorchScript en `../models/`\n",
    "\n",
    "Si ves errores de tama√±o de tensores al apilar batches, aseg√∫rate de que los audios tengan **duraci√≥n similar** o av√≠same para a√±adir padding/cropping autom√°tico.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c34eaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root added to sys.path: D:\\UMNG-2025\\FakeVoice\\FakeVoice\n"
     ]
    }
   ],
   "source": [
    "# 1) Rutas y pathing del proyecto (este notebook vive en notebooks/)\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "lib_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if lib_path not in sys.path:\n",
    "    sys.path.insert(0, lib_path)\n",
    "print(\"Project root added to sys.path:\", lib_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27312e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Imports principales\n",
    "from pprint import pprint\n",
    "from fakevoicefinder import ExperimentConfig, CreateExperiment, ModelLoader, Trainer, ConfigError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "526d958d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config validation ‚úÖ\n",
      "ExperimentConfig:\n",
      "  batch_size     : 8\n",
      "  cache_features : True\n",
      "  data_path      : ../dataset\n",
      "  device         : gpu\n",
      "  epochs         : 1\n",
      "  eval_metric    : ['accuracy', 'F1']\n",
      "  fakes_zip      : fakes.zip\n",
      "  flag_train     : True\n",
      "  input_channels : 1\n",
      "  learning_rate  : 0.003\n",
      "  models_list    : ['alexnet', 'vgg16', 'resnet18']\n",
      "  models_path    : ../models\n",
      "  num_workers    : 4\n",
      "  optimizer      : Adam\n",
      "  outputs_path   : outputs\n",
      "  patience       : 3\n",
      "  reals_zip      : reals.zip\n",
      "  run_name       : exp_bench_v10\n",
      "  save_best_only : True\n",
      "  save_models    : True\n",
      "  seed           : 23\n",
      "  transform_list : ['mel']\n",
      "  type_train     : pretrain\n"
     ]
    }
   ],
   "source": [
    "# 3) Configuraci√≥n del experimento\n",
    "cfg = ExperimentConfig()\n",
    "\n",
    "# Nombre del experimento (carpeta bajo outputs/)\n",
    "cfg.run_name = \"exp_bench_v10\"\n",
    "\n",
    "# Ubicaciones (repo-relativas)\n",
    "cfg.data_path = \"../dataset\"   # donde est√°n reals.zip y fakes.zip\n",
    "cfg.models_path = \"../models\"  # por si a√±ades modelos de usuario TorchScript\n",
    "\n",
    "# Transforms a generar (puedes dejar solo 'mel' para ir m√°s r√°pido)\n",
    "cfg.transform_list = [\"mel\"]  # [\"mel\", \"log\"]\n",
    "\n",
    "# Modelos benchmark a probar\n",
    "cfg.models_list = [\"alexnet\",\"vgg16\", \"resnet18\"]\n",
    "\n",
    "# Entrenamiento r√°pido de smoke-test\n",
    "cfg.type_train = \"pretrain\"   # 'scratch' | 'pretrain' | 'both'\n",
    "cfg.epochs = 1\n",
    "cfg.batch_size = 8\n",
    "cfg.learning_rate = 3e-3\n",
    "cfg.patience = 3\n",
    "\n",
    "# Canal de entrada de los espectrogramas (.npy): 1 canal\n",
    "cfg.input_channels = 1  # <- no est√° en la clase, pero ModelLoader lo respeta v√≠a getattr(..., 3)\n",
    "\n",
    "# Validaci√≥n de la config\n",
    "try:\n",
    "    cfg.validate()\n",
    "    print(\"Config validation ‚úÖ\")\n",
    "except ConfigError as e:\n",
    "    print(\"Config validation error:\", e)\n",
    "    raise\n",
    "\n",
    "print(cfg.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62fe9e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gpach\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated and will be removed in a future release\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data prep summary:\n",
      "{'load': {'fakes': 107, 'reals': 824},\n",
      " 'save_original': {'test': 187, 'train': 744},\n",
      " 'split': {'test': {'fakes': 21, 'reals': 166, 'total': 187},\n",
      "           'train': {'fakes': 86, 'reals': 658, 'total': 744}},\n",
      " 'transforms': {'mel': {'test': 183, 'train': 656}}}\n",
      "Manifest: D:/UMNG-2025/FakeVoice/FakeVoice/outputs/exp_bench_v10/experiment.json\n"
     ]
    }
   ],
   "source": [
    "# 4) Crear experimento y preparar datos\n",
    "exp = CreateExperiment(cfg, experiment_name=cfg.run_name)\n",
    "exp.build()\n",
    "\n",
    "summary = exp.prepare_data(train_ratio=0.8, seed=cfg.seed, transforms=cfg.transform_list)\n",
    "print(\"Data prep summary:\")\n",
    "pprint(summary)\n",
    "\n",
    "print(\"Manifest:\", (exp.root / \"experiment.json\").as_posix())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48f90718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarks saved under models/loaded:\n",
      "{'alexnet': {'pretrain': 'outputs/exp_bench_v10/models/loaded/alexnet_pretrain.pt'},\n",
      " 'resnet18': {'pretrain': 'outputs/exp_bench_v10/models/loaded/resnet18_pretrain.pt'},\n",
      " 'vgg16': {'pretrain': 'outputs/exp_bench_v10/models/loaded/vgg16_pretrain.pt'}}\n"
     ]
    }
   ],
   "source": [
    "# 5) Cargar y guardar modelos benchmark (loaded variants)\n",
    "loader = ModelLoader(exp)\n",
    "bench = loader.prepare_benchmarks(add_softmax=True, input_channels=getattr(cfg, \"input_channels\", 1))\n",
    "print(\"Benchmarks saved under models/loaded:\")\n",
    "pprint(bench)\n",
    "\n",
    "# User models (if any .pt/.pth under cfg.models_path)\n",
    "#user = loader.prepare_user_models(add_softmax=True, input_channels=cfg.input_channels)\n",
    "#print(\"User models saved:\")\n",
    "#pprint(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24767786-8c87-4048-bc93-b3efeea47a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ datasets\n",
      "   üìÅ test\n",
      "      üìÅ original\n",
      "         üìÅ fakes\n",
      "         üìÅ reals\n",
      "      üìÅ transforms\n",
      "         üìÅ mel\n",
      "   üìÅ train\n",
      "      üìÅ original\n",
      "         üìÅ fakes\n",
      "         üìÅ reals\n",
      "      üìÅ transforms\n",
      "         üìÅ mel\n",
      "üìÅ models\n",
      "   üìÅ loaded\n",
      "      üìÑ alexnet_pretrain.pt\n",
      "      üìÑ resnet18_pretrain.pt\n",
      "      üìÑ vgg16_pretrain.pt\n",
      "   üìÅ trained\n",
      "üìÑ experiment.json\n"
     ]
    }
   ],
   "source": [
    "def print_tree(root: Path, max_depth: int = 3, prefix: str = \"\"):\n",
    "    if max_depth < 0:\n",
    "        return\n",
    "    try:\n",
    "        entries = sorted(root.iterdir(), key=lambda p: (p.is_file(), p.name.lower()))\n",
    "    except FileNotFoundError:\n",
    "        return\n",
    "    for e in entries:\n",
    "        print(prefix + (\"üìÑ \" if e.is_file() else \"üìÅ \") + e.name)\n",
    "        if e.is_dir():\n",
    "            print_tree(e, max_depth - 1, prefix + \"   \")\n",
    "\n",
    "print_tree(exp.root, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f6b966a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trainer] Using device: cuda\n",
      "[Trainer] Transforms to train: ['mel']\n",
      "[Trainer] Models found: ['alexnet', 'vgg16', 'resnet18']\n",
      "\n",
      "=== MODEL: alexnet ===\n",
      "[alexnet] Hyperparams -> epochs=1, lr=0.003, bs=8, optimizer=Adam, patience=3, seed=23, num_workers=4\n",
      "[alexnet][mel] Dataset sizes -> train: 656, test: 183\n",
      "[alexnet][mel] Batches -> train: 82, test: 23\n",
      "[alexnet][mel][pretrain] Loading checkpoint: D:\\UMNG-2025\\FakeVoice\\FakeVoice\\outputs\\exp_bench_v10\\models\\loaded\\alexnet_pretrain.pt\n",
      "[alexnet][mel][pretrain] Loaded pickled module.\n",
      "[alexnet][mel][pretrain] Start training for 1 epochs\n",
      "[alexnet][mel][pretrain] Epoch 1/1 - loss=0.4472 acc=0.8852 (10.1s)\n",
      "[alexnet][mel][pretrain] ‚úÖ New best acc=0.8852 at epoch 1\n",
      "[alexnet][mel][pretrain] Saved best checkpoint -> alexnet_pretrain_mel_seed23_epoch001_acc0.89.pt\n",
      "[alexnet][mel] Trained variants: {'pretrain': 'outputs/exp_bench_v10/models/trained/alexnet_pretrain_mel_seed23_epoch001_acc0.89.pt'}\n",
      "\n",
      "=== MODEL: vgg16 ===\n",
      "[vgg16] Hyperparams -> epochs=1, lr=0.003, bs=8, optimizer=Adam, patience=3, seed=23, num_workers=4\n",
      "[vgg16][mel] Dataset sizes -> train: 656, test: 183\n",
      "[vgg16][mel] Batches -> train: 82, test: 23\n",
      "[vgg16][mel][pretrain] Loading checkpoint: D:\\UMNG-2025\\FakeVoice\\FakeVoice\\outputs\\exp_bench_v10\\models\\loaded\\vgg16_pretrain.pt\n",
      "[vgg16][mel][pretrain] Loaded pickled module.\n",
      "[vgg16][mel][pretrain] Start training for 1 epochs\n",
      "[vgg16][mel][pretrain] Epoch 1/1 - loss=0.4483 acc=0.8852 (12.4s)\n",
      "[vgg16][mel][pretrain] ‚úÖ New best acc=0.8852 at epoch 1\n",
      "[vgg16][mel][pretrain] Saved best checkpoint -> vgg16_pretrain_mel_seed23_epoch001_acc0.89.pt\n",
      "[vgg16][mel] Trained variants: {'pretrain': 'outputs/exp_bench_v10/models/trained/vgg16_pretrain_mel_seed23_epoch001_acc0.89.pt'}\n",
      "\n",
      "=== MODEL: resnet18 ===\n",
      "[resnet18] Hyperparams -> epochs=1, lr=0.003, bs=8, optimizer=Adam, patience=3, seed=23, num_workers=4\n",
      "[resnet18][mel] Dataset sizes -> train: 656, test: 183\n",
      "[resnet18][mel] Batches -> train: 82, test: 23\n",
      "[resnet18][mel][pretrain] Loading checkpoint: D:\\UMNG-2025\\FakeVoice\\FakeVoice\\outputs\\exp_bench_v10\\models\\loaded\\resnet18_pretrain.pt\n",
      "[resnet18][mel][pretrain] Loaded pickled module.\n",
      "[resnet18][mel][pretrain] Start training for 1 epochs\n",
      "[resnet18][mel][pretrain] Epoch 1/1 - loss=0.4472 acc=0.8852 (10.1s)\n",
      "[resnet18][mel][pretrain] ‚úÖ New best acc=0.8852 at epoch 1\n",
      "[resnet18][mel][pretrain] Saved best checkpoint -> resnet18_pretrain_mel_seed23_epoch001_acc0.89.pt\n",
      "[resnet18][mel] Trained variants: {'pretrain': 'outputs/exp_bench_v10/models/trained/resnet18_pretrain_mel_seed23_epoch001_acc0.89.pt'}\n",
      "\n",
      "[Trainer] All training finished.\n",
      "Resultados de entrenamiento (rutas repo-relativas):\n",
      "{'alexnet': {'mel': {'pretrain': 'outputs/exp_bench_v10/models/trained/alexnet_pretrain_mel_seed23_epoch001_acc0.89.pt'}},\n",
      " 'resnet18': {'mel': {'pretrain': 'outputs/exp_bench_v10/models/trained/resnet18_pretrain_mel_seed23_epoch001_acc0.89.pt'}},\n",
      " 'vgg16': {'mel': {'pretrain': 'outputs/exp_bench_v10/models/trained/vgg16_pretrain_mel_seed23_epoch001_acc0.89.pt'}}}\n",
      "Best checkpoints stored in: D:/UMNG-2025/FakeVoice/FakeVoice/outputs/exp_bench_v10/models/trained\n"
     ]
    }
   ],
   "source": [
    "# 6) Entrenar TODO (cada variante por cada transform)\n",
    "trainer = Trainer(exp)\n",
    "train_results = trainer.train_all()\n",
    "print(\"Resultados de entrenamiento (rutas repo-relativas):\")\n",
    "pprint(train_results)\n",
    "\n",
    "print(\"Best checkpoints stored in:\", (exp.trained_models).as_posix())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
