{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86a78941",
   "metadata": {},
   "source": [
    "# Benchmark Training: VGG, ResNet, ViT\n",
    "\n",
    "Este notebook prepara datos desde los ZIPs (`reals.zip`, `fakes.zip`), carga modelos **benchmark** de torchvision (VGG, ResNet, ViT) seg√∫n tu config y entrena **1 √©poca** por transformaci√≥n.\n",
    "\n",
    "**Requisitos previos**:\n",
    "- Carpeta del notebook: `notebooks/`\n",
    "- Zips en `../dataset/` (al nivel del repo): `reals.zip`, `fakes.zip`\n",
    "- (Opcional) modelos de usuario TorchScript en `../models/`\n",
    "\n",
    "Si ves errores de tama√±o de tensores al apilar batches, aseg√∫rate de que los audios tengan **duraci√≥n similar** o av√≠same para a√±adir padding/cropping autom√°tico.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c34eaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root added to sys.path: D:\\UMNG-2025\\FakeVoice\\FakeVoice\n"
     ]
    }
   ],
   "source": [
    "# 1) Rutas y pathing del proyecto (este notebook vive en notebooks/)\n",
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "lib_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "if lib_path not in sys.path:\n",
    "    sys.path.insert(0, lib_path)\n",
    "print(\"Project root added to sys.path:\", lib_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27312e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Imports principales\n",
    "from pprint import pprint\n",
    "from fakevoicefinder import ExperimentConfig, CreateExperiment, ModelLoader, Trainer, ConfigError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "526d958d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config validation ‚úÖ\n",
      "ExperimentConfig:\n",
      "  batch_size     : 8\n",
      "  cache_features : True\n",
      "  data_path      : ../dataset\n",
      "  device         : gpu\n",
      "  epochs         : 1\n",
      "  eval_metric    : ['accuracy', 'F1']\n",
      "  fakes_zip      : fakes.zip\n",
      "  flag_train     : True\n",
      "  input_channels : 1\n",
      "  learning_rate  : 0.003\n",
      "  models_list    : ['vgg16', 'resnet18', 'vit_b_16']\n",
      "  models_path    : ../models\n",
      "  num_workers    : 4\n",
      "  optimizer      : Adam\n",
      "  outputs_path   : outputs\n",
      "  patience       : 3\n",
      "  reals_zip      : reals.zip\n",
      "  run_name       : exp_bench_v1\n",
      "  save_best_only : True\n",
      "  save_models    : True\n",
      "  seed           : 23\n",
      "  transform_list : ['mel']\n",
      "  type_train     : pretrain\n"
     ]
    }
   ],
   "source": [
    "# 3) Configuraci√≥n del experimento\n",
    "cfg = ExperimentConfig()\n",
    "\n",
    "# Nombre del experimento (carpeta bajo outputs/)\n",
    "cfg.run_name = \"exp_bench_v1\"\n",
    "\n",
    "# Ubicaciones (repo-relativas)\n",
    "cfg.data_path = \"../dataset\"   # donde est√°n reals.zip y fakes.zip\n",
    "cfg.models_path = \"../models\"  # por si a√±ades modelos de usuario TorchScript\n",
    "\n",
    "# Transforms a generar (puedes dejar solo 'mel' para ir m√°s r√°pido)\n",
    "cfg.transform_list = [\"mel\"]  # [\"mel\", \"log\"]\n",
    "\n",
    "# Modelos benchmark a probar\n",
    "cfg.models_list = [\"vgg16\", \"resnet18\", \"vit_b_16\"]\n",
    "\n",
    "# Entrenamiento r√°pido de smoke-test\n",
    "cfg.type_train = \"pretrain\"   # 'scratch' | 'pretrain' | 'both'\n",
    "cfg.epochs = 1\n",
    "cfg.batch_size = 8\n",
    "cfg.learning_rate = 3e-3\n",
    "cfg.patience = 3\n",
    "\n",
    "# Canal de entrada de los espectrogramas (.npy): 1 canal\n",
    "cfg.input_channels = 1  # <- no est√° en la clase, pero ModelLoader lo respeta v√≠a getattr(..., 3)\n",
    "\n",
    "# Validaci√≥n de la config\n",
    "try:\n",
    "    cfg.validate()\n",
    "    print(\"Config validation ‚úÖ\")\n",
    "except ConfigError as e:\n",
    "    print(\"Config validation error:\", e)\n",
    "    raise\n",
    "\n",
    "print(cfg.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62fe9e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gpach\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated and will be removed in a future release\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data prep summary:\n",
      "{'load': {'fakes': 107, 'reals': 824},\n",
      " 'save_original': {'test': 187, 'train': 744},\n",
      " 'split': {'test': {'fakes': 21, 'reals': 166, 'total': 187},\n",
      "           'train': {'fakes': 86, 'reals': 658, 'total': 744}},\n",
      " 'transforms': {'mel': {'test': 183, 'train': 656}}}\n",
      "Manifest: D:/UMNG-2025/FakeVoice/FakeVoice/outputs/exp_bench_v1/experiment.json\n"
     ]
    }
   ],
   "source": [
    "# 4) Crear experimento y preparar datos\n",
    "exp = CreateExperiment(cfg, experiment_name=cfg.run_name)\n",
    "exp.build()\n",
    "\n",
    "summary = exp.prepare_data(train_ratio=0.8, seed=cfg.seed, transforms=cfg.transform_list)\n",
    "print(\"Data prep summary:\")\n",
    "pprint(summary)\n",
    "\n",
    "print(\"Manifest:\", (exp.root / \"experiment.json\").as_posix())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48f90718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarks saved under models/loaded:\n",
      "{'resnet18': {'pretrain': 'outputs/exp_bench_v1/models/loaded/resnet18_pretrain.pt'},\n",
      " 'vgg16': {'pretrain': 'outputs/exp_bench_v1/models/loaded/vgg16_pretrain.pt'},\n",
      " 'vit_b_16': {'pretrain': 'outputs/exp_bench_v1/models/loaded/vit_b_16_pretrain.pt'}}\n",
      "User models saved:\n",
      "{'SimpleCNN_scripted.pt': 'outputs/exp_bench_v1/models/loaded/SimpleCNN_scripted_usermodel_jit.pt'}\n"
     ]
    }
   ],
   "source": [
    "# 5) Cargar y guardar modelos benchmark (loaded variants)\n",
    "loader = ModelLoader(exp)\n",
    "bench = loader.prepare_benchmarks(add_softmax=True, input_channels=getattr(cfg, \"input_channels\", 1))\n",
    "print(\"Benchmarks saved under models/loaded:\")\n",
    "pprint(bench)\n",
    "\n",
    "# User models (if any .pt/.pth under cfg.models_path)\n",
    "user = loader.prepare_user_models(add_softmax=True, input_channels=cfg.input_channels)\n",
    "print(\"User models saved:\")\n",
    "pprint(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24767786-8c87-4048-bc93-b3efeea47a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ datasets\n",
      "   üìÅ test\n",
      "      üìÅ original\n",
      "         üìÅ fakes\n",
      "         üìÅ reals\n",
      "      üìÅ transforms\n",
      "         üìÅ mel\n",
      "   üìÅ train\n",
      "      üìÅ original\n",
      "         üìÅ fakes\n",
      "         üìÅ reals\n",
      "      üìÅ transforms\n",
      "         üìÅ mel\n",
      "üìÅ models\n",
      "   üìÅ loaded\n",
      "      üìÑ resnet18_pretrain.pt\n",
      "      üìÑ SimpleCNN_scripted_usermodel_jit.pt\n",
      "      üìÑ vgg16_pretrain.pt\n",
      "      üìÑ vit_b_16_pretrain.pt\n",
      "   üìÅ trained\n",
      "üìÑ experiment.json\n"
     ]
    }
   ],
   "source": [
    "def print_tree(root: Path, max_depth: int = 3, prefix: str = \"\"):\n",
    "    if max_depth < 0:\n",
    "        return\n",
    "    try:\n",
    "        entries = sorted(root.iterdir(), key=lambda p: (p.is_file(), p.name.lower()))\n",
    "    except FileNotFoundError:\n",
    "        return\n",
    "    for e in entries:\n",
    "        print(prefix + (\"üìÑ \" if e.is_file() else \"üìÅ \") + e.name)\n",
    "        if e.is_dir():\n",
    "            print_tree(e, max_depth - 1, prefix + \"   \")\n",
    "\n",
    "print_tree(exp.root, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f6b966a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Wrong image height! Expected 224 but got 128!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 6) Entrenar TODO (cada variante por cada transform)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(exp)\n\u001b[1;32m----> 3\u001b[0m train_results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtrain_all()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResultados de entrenamiento (rutas repo-relativas):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m pprint(train_results)\n",
      "File \u001b[1;32mD:\\UMNG-2025\\FakeVoice\\FakeVoice\\fakevoicefinder\\trainer.py:184\u001b[0m, in \u001b[0;36mTrainer.train_all\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    181\u001b[0m     model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    182\u001b[0m     torch\u001b[38;5;241m.\u001b[39mmanual_seed(seed)\n\u001b[1;32m--> 184\u001b[0m     best_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_one(\n\u001b[0;32m    185\u001b[0m         model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    186\u001b[0m         train_loader\u001b[38;5;241m=\u001b[39mtrain_loader,\n\u001b[0;32m    187\u001b[0m         test_loader\u001b[38;5;241m=\u001b[39mtest_loader,\n\u001b[0;32m    188\u001b[0m         epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[0;32m    189\u001b[0m         lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[0;32m    190\u001b[0m         optimizer_name\u001b[38;5;241m=\u001b[39moptim_name,\n\u001b[0;32m    191\u001b[0m         patience\u001b[38;5;241m=\u001b[39mpatience,\n\u001b[0;32m    192\u001b[0m         model_name\u001b[38;5;241m=\u001b[39mmodel_name,\n\u001b[0;32m    193\u001b[0m         variant\u001b[38;5;241m=\u001b[39mvariant,\n\u001b[0;32m    194\u001b[0m         transform\u001b[38;5;241m=\u001b[39mtransform,\n\u001b[0;32m    195\u001b[0m         seed\u001b[38;5;241m=\u001b[39mseed,\n\u001b[0;32m    196\u001b[0m         save_as\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpickle\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# saved as .pt (pickled)\u001b[39;00m\n\u001b[0;32m    197\u001b[0m     )\n\u001b[0;32m    198\u001b[0m     trained_for_transform[variant] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_repo_rel(best_path)\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m variant \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musermodel_jit\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;66;03m# TorchScript user model: load module and train as-is (no surgery)\u001b[39;00m\n",
      "File \u001b[1;32mD:\\UMNG-2025\\FakeVoice\\FakeVoice\\fakevoicefinder\\trainer.py:329\u001b[0m, in \u001b[0;36mTrainer._train_one\u001b[1;34m(self, model, train_loader, test_loader, epochs, lr, optimizer_name, patience, model_name, variant, transform, seed, save_as)\u001b[0m\n\u001b[0;32m    327\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    328\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 329\u001b[0m logits \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[0;32m    330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(logits, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[0;32m    331\u001b[0m     logits \u001b[38;5;241m=\u001b[39m logits[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\models\\vision_transformer.py:291\u001b[0m, in \u001b[0;36mVisionTransformer.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;66;03m# Reshape and permute the input tensor\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_input(x)\n\u001b[0;32m    292\u001b[0m     n \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;66;03m# Expand the class token to the full batch\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\models\\vision_transformer.py:271\u001b[0m, in \u001b[0;36mVisionTransformer._process_input\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    269\u001b[0m n, c, h, w \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    270\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_size\n\u001b[1;32m--> 271\u001b[0m torch\u001b[38;5;241m.\u001b[39m_assert(h \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_size, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrong image height! Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    272\u001b[0m torch\u001b[38;5;241m.\u001b[39m_assert(w \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_size, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrong image width! Expected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mw\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    273\u001b[0m n_h \u001b[38;5;241m=\u001b[39m h \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m p\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\__init__.py:2132\u001b[0m, in \u001b[0;36m_assert\u001b[1;34m(condition, message)\u001b[0m\n\u001b[0;32m   2126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(condition) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;129;01mand\u001b[39;00m overrides\u001b[38;5;241m.\u001b[39mhas_torch_function(\n\u001b[0;32m   2127\u001b[0m     (condition,)\n\u001b[0;32m   2128\u001b[0m ):\n\u001b[0;32m   2129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m overrides\u001b[38;5;241m.\u001b[39mhandle_torch_function(\n\u001b[0;32m   2130\u001b[0m         _assert, (condition,), condition, message\n\u001b[0;32m   2131\u001b[0m     )\n\u001b[1;32m-> 2132\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m condition, message\n",
      "\u001b[1;31mAssertionError\u001b[0m: Wrong image height! Expected 224 but got 128!"
     ]
    }
   ],
   "source": [
    "# 6) Entrenar TODO (cada variante por cada transform)\n",
    "trainer = Trainer(exp)\n",
    "train_results = trainer.train_all()\n",
    "print(\"Resultados de entrenamiento (rutas repo-relativas):\")\n",
    "pprint(train_results)\n",
    "\n",
    "print(\"Best checkpoints stored in:\", (exp.trained_models).as_posix())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257d06a1",
   "metadata": {},
   "source": [
    "### Notas\n",
    "- Si aparece `RuntimeError: stack expects each tensor to be equal size`, tus espectrogramas (W) tienen longitud variable.\n",
    "  Podemos a√±adir **padding/cropping autom√°tico** en el `Trainer` o fijar una duraci√≥n objetivo al transformar.\n",
    "- Para probar m√°s r√°pido: usa solo `mel`, baja `sample_rate` y reduce `batch_size`.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
